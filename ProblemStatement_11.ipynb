{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run below code in scala spark-shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import org.apache.spark.SparkContext\n",
    "\n",
    "# val sc = new SparkContext()\n",
    "# var map = sc.textFile(\"/mnt/spark/bin/sample.txt\").flatMap(line=>line.split(\" \")).map(word=>(word,1));\n",
    "# println(map)\n",
    "\n",
    "# var counts = map.reduceByKey(_+_);\n",
    "# println(\"Max\",counts.max)\n",
    "\n",
    "# var valu = counts.values\n",
    "# println(\"count = \",counts.count)\n",
    "# counts.collect\n",
    "\n",
    "# val m = counts.max\n",
    "# counts.saveAsTextFile(\"/mnt/spark/bin/cnt_fri\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
